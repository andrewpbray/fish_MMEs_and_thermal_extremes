---
title: "Assess Models"
author: "Aaron Till and Andrew Bray"
output: html_document
---

Candidate models are compared in terms of their coefficients to check for sensitivity of the coefficients to modeling choices, and their out-of-sample predictive performance, assessed using logloss
and ROC-AUC.

```{r}
library(tidyverse)
library(caret)
library(glmnet)
library(Matrix)
library(e1071)
library(broom)
library(yardstick)
```

## Load partitioned data

```{r}
setwd("data/prepared_for_modeling/")
training <- read_csv("training.csv",
                     col_types = list(wbic = col_character(),
                                      year = col_character(),
                                      month  = col_character(),
                                      season = col_character(),
                                      summerkill = col_character(),
                                      ice_duration = col_double())) %>%
  mutate(summerkill = as.factor(summerkill))

testing <- read_csv("testing.csv",
                    col_types = list(wbic = col_character(),
                                     year = col_character(),
                                     month  = col_character(),
                                     season = col_character(),
                                     ice_duration = col_double())) %>%
  mutate(summerkill = as.factor(summerkill))
```

## Load models

```{r}
setwd("../models/assessment") 
model_names <- list.files()
all_models <- model_names %>%
  map(., ~read_rds(.x))
all_models <- tibble(name  = str_sub(str_extract(model_names, "^.*\\."), 
                                     1, -2),
                     model = all_models)
```

## Metrics

Extract fitted values and append as new column.

```{r}
predict_route <- function(model, newdata) {
  if("train" %in% class(model)) {
    predict(model, newdata, type = "prob")$pos
  } else {predict(model, newdata, type = "response")}
}

all_models <- all_models %>%
  mutate(fit_test = map(model, predict_route, newdata = testing))
```

Calculate logloss and auc.

```{r}
# the following can be made more concise w map()
auc <- rep(NA, nrow(all_models))
logloss <- auc
for (i in 1:nrow(all_models)) {
  a <- tibble(fit_test = all_models$fit_test[[i]],
              truth    = testing$summerkill)
  auc[i] <- roc_auc(a, truth, fit_test)$.estimate
  logloss[i] <- mn_log_loss(a, truth, fit_test)$.estimate
}

all_models %>%
  add_column(auc, logloss) %>%
  arrange(desc(auc), logloss)
```

## Coefficients

Extract coefficients from each model.

```{r}
extract_coef <- function(model, name) {
  if ("train" %in% class(model)) {
    m <- model$finalModel %>%
      coef(model$bestTune$lambda)
    out <- tibble(term = row.names(m),
                  estimate = m[, 1]) %>%
      filter(term != "(Intercept)") %>%
      select(term, estimate)
  }
  if ("glmerMod" %in% class(model)) {
    out <- model %>%
      tidy() %>%
      filter(group == "fixed") %>%
      filter(term != "(Intercept)") %>%
      filter(p.value <= .3) %>%
      select(term, estimate)
  }
  if ("glm" %in% class(model)) {
    out <- model %>%
      tidy() %>%
      filter(term != "(Intercept)") %>%
      select(term, estimate)
  }
  out
}

all_models <- all_models %>%
  mutate(coef = map2(model, name, extract_coef))
```

Plot coefficients.

```{r}
all_models %>%
  unnest(coef) %>%
  ggplot(aes(x = fct_reorder(term, estimate), 
             y = estimate, 
             fill = estimate > 0)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ name, ncol = 4) +
  coord_flip() +
  labs(x = NULL) +
  theme_bw()
```



