---
title: "Modeling"
author: "Aaron Till and Andrew Bray"
output: html_document
---

```{r}
library(tidyverse)
library(caret)
library(glmnet)
library(Matrix)
library(e1071)
```

## Prepare data

```{r}
setwd("data/processed/")
historical_data <- read_csv("historical_data.csv")
historical_data <- historical_data %>%
  mutate(summerkill = factor(ifelse(is.na(summerkill), 0, summerkill)))
future_data     <- read_csv("future_data.csv")
```

## Model 1: Lasso Logistic

### Tune model

First we must create the training and testing partitions. We begin this naively,
taking an SRS approach instead of a moving-windows time-series approach.

```{r}
set.seed(998)
in_training <- createDataPartition(historical_data$summerkill,
                                  p = .75, list = FALSE)
training <- historical_data %>%
  slice(in_training) %>%
  select(lat, lon, schmidt, variance_after_ice_30,
         variance_after_ice_60, cumulative_above_0,
         cumulative_above_5,  cumulative_above_10,
         max_surf, mean_bot, max_bot, mean_surf, 
         max_surf_z, mean_bot_z, max_bot_z, mean_surf_z, 
         summerkill, population)

testing  <- historical_data %>%
  slice(-in_training) %>%
  select(lat, lon, schmidt, variance_after_ice_30,
         variance_after_ice_60, cumulative_above_0,
         cumulative_above_5,  cumulative_above_10,
         max_surf, mean_bot, max_bot, mean_surf, 
         max_surf_z, mean_bot_z, max_bot_z, mean_surf_z, 
         summerkill, population)
```

In order to compare coefficients, we center and scale the predictors.

```{r}
pre_proc_values <- preProcess(training, method = c("center", "scale"))
train_transformed <- predict(pre_proc_values, training)
test_transformed  <- predict(pre_proc_values, testing)
```


Next we fit LASSO models with many difference lambdas, utilizing a 10-fold CV
scheme, repeated 10 times, on the training data.

```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 1)

library(doParallel)
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

set.seed(825)
lasso_fit_1 <- train(summerkill ~ ., data = train_transformed, 
                 method = "glmnet", 
                 trControl = fitControl)

lasso_fit_1b <- train(summerkill ~ ., data = training, 
                 method = "glmnet", 
                 trControl = fitControl)

stopCluster(cl)
write_rds(lasso_fit_1, "../lasso_fit_1.rds")
write_rds(lasso_fit_1b, "../lasso_fit_1b.rds")
```


### Assess model

Next we see if we can recreate fig 2 using the predictions from this model.

```{r eval = FALSE}
future_test <- future_data %>%
  select(lat, lon, schmidt, variance_after_ice_30,
         variance_after_ice_60, cumulative_above_0,
         cumulative_above_5,  cumulative_above_10,
         max_surf, mean_bot, max_bot, mean_surf, 
         max_surf_z, mean_bot_z, max_bot_z, 
         mean_surf_z, population)

lasso_fit_1 <- read_rds("../models/lasso_fit_1.rds")
predictions_1 <- predict(object=lasso_fit_1, future_test,
                       type = "prob") %>%
  select(2)

df_fig_2 <- future_data %>%
  select(year) %>%
  bind_cols(predictions_1) %>%
  group_by(year) %>%
  summarize(MMEs = sum(`1`))

df_fig_2 %>%
  ggplot(aes(x = year, y = MMEs)) +
  geom_bar(stat="identity")
```

Compute likelihood on testing data.

```{r eval = FALSE}
test_true <- as.logical(as.integer(as.character(testing$summerkill)))
L_1 <- predict(object=lasso_fit_1, select(testing, -summerkill),
               type = "prob") %>%
  select(`1`) %>%
  mutate(`0` = 1 - `1`) %>%
  add_column(test_true) %>%
  mutate(term_0 = `0` * !test_true,
         term_1 = `1` * test_true,
         term = term_0 + term_1) %>%
  pull(term) %>% prod()
```


## Model 2: Lasso logistic with season fixed effects

### Fit model

```{r}
training <- historical_data %>%
  slice(in_training) %>%
  select(lat, lon, schmidt, variance_after_ice_30,
         variance_after_ice_60, cumulative_above_0,
         cumulative_above_5,  cumulative_above_10,
         max_surf, mean_bot, max_bot, mean_surf, 
         max_surf_z, mean_bot_z, max_bot_z, mean_surf_z, 
         summerkill, population, season) %>%
  mutate(season = as_factor(season))

testing  <- historical_data %>%
  slice(-in_training) %>%
  select(lat, lon, schmidt, variance_after_ice_30,
         variance_after_ice_60, cumulative_above_0,
         cumulative_above_5,  cumulative_above_10,
         max_surf, mean_bot, max_bot, mean_surf, 
         max_surf_z, mean_bot_z, max_bot_z, mean_surf_z, 
         summerkill, population, season) %>%
  mutate(season = as_factor(season))
```

```{r}
pre_proc_values <- preProcess(training, method = c("center", "scale"))
train_transformed <- predict(pre_proc_values, training)
test_transformed  <- predict(pre_proc_values, testing)
```

```{r}
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

set.seed(825)
lasso_fit_2 <- train(summerkill ~ ., data = training, 
                 method = "glmnet", 
                 trControl = fitControl)

stopCluster(cl)
write_rds(lasso_fit_2, "../lasso_fit_2.rds")
```

### Assess model

```{r eval = FALSE}
future_test <- future_data %>%
  select(lat, lon, schmidt, variance_after_ice_30,
         variance_after_ice_60, cumulative_above_0,
         cumulative_above_5,  cumulative_above_10,
         max_surf, mean_bot, max_bot, mean_surf, 
         max_surf_z, mean_bot_z, max_bot_z, 
         mean_surf_z, population, season) %>%
  mutate(season = as_factor(season))

lasso_fit_2 <- read_rds("../models/lasso_fit_2.rds")
predictions_2 <- predict(object=lasso_fit_2, future_test,
                       type = "prob") %>%
  select(2)

df_fig_2 <- future_data %>%
  select(year) %>%
  bind_cols(predictions_2) %>%
  group_by(year) %>%
  summarize(MMEs = sum(`1`))

df_fig_2 %>%
  ggplot(aes(x = year, y = MMEs)) +
  geom_bar(stat="identity")
```

Compute likelihood on testing data.

```{r eval = FALSE}
test_true <- as.logical(as.integer(as.character(testing$summerkill)))
L_2 <- predict(object=lasso_fit_2, select(testing, -summerkill),
               type = "prob") %>%
  select(`1`) %>%
  mutate(`0` = 1 - `1`) %>%
  add_column(test_true) %>%
  mutate(term_0 = `0` * !test_true,
         term_1 = `1` * test_true,
         term = term_0 + term_1) %>%
  pull(term) %>% prod()
```

## Model 3: Lasso logistic with month fixed effects


### Assess model

```{r, eval = FALSE}
lasso_fit_3 <- read_rds("../models/lasso_fit_3.rds")

future_test <- future_data %>%
  select(lat, lon, schmidt, variance_after_ice_30,
         variance_after_ice_60, cumulative_above_0,
         cumulative_above_5,  cumulative_above_10,
         max_surf, mean_bot, max_bot, mean_surf, 
         max_surf_z, mean_bot_z, max_bot_z, 
         mean_surf_z, population, month) %>%
  mutate(season = as_factor(month))

predictions_3 <- predict(object=lasso_fit_3, future_test,
                       type = "prob") %>%
  select(2)

df_fig_2 <- future_data %>%
  select(year) %>%
  bind_cols(predictions_3) %>%
  group_by(year) %>%
  summarize(MMEs = sum(`1`))

df_fig_2 %>%
  ggplot(aes(x = year, y = MMEs)) +
  geom_bar(stat="identity")
```

Compute likelihood on testing data.

```{r eval = FALSE}
test_true <- as.logical(as.integer(as.character(testing$summerkill)))
L_3 <- predict(object=lasso_fit_3, select(testing, -summerkill),
               type = "prob") %>%
  select(`1`) %>%
  mutate(`0` = 1 - `1`) %>%
  add_column(test_true) %>%
  mutate(term_0 = `0` * !test_true,
         term_1 = `1` * test_true,
         term = term_0 + term_1) %>%
  pull(term) %>% prod()
```


## Compare all 3

```{r eval = FALSE}
plot(varImp(lasso_fit_1,scale=T))
plot(varImp(lasso_fit_2,scale=F))
plot(varImp(lasso_fit_3,scale=F))

library(pROC)
predictions <- as.numeric(predict(object=lasso_fit_1, select(testing, -summerkill)))
roc(testing$summerkill, predictions)
```

Compare likelihoods.

```{r eval = FALSE}
L_1
L_2
L_3
```




# THE FOLLOWING CODE HAS NOT YET BEEN REVISED

# Lasso regression 

```{r}
x_lasso <- model.matrix(summerkill ~ . , modeling_data)
y_lasso <- modeling_data$summerkill == 1
```

```{r}
lambdatest <- glmnet(x_lasso, y_lasso, family = "binomial", alpha = 1)
plot(lambdatest, xvar = 'lambda')
```

```{r observing lambdas}
set.seed(1234)

grid <- 10^seq(10, -15, length = 100) 
# set lambda equal to for checking if more extensive lambda needed, no difference

# for quicker, lambda = c(10^-7, 10^-5.5, 10^-4)
lasso_regression_coords_lambda_summer <- cv.glmnet(x_lasso, y_lasso, family = "binomial",
                                                   lambda = c(10^-7, 10^-5.5, 10^-4), 
                                                   alpha = 1, nfolds = 3)

plot(lasso_regression_coords_lambda_summer)

```

```{r making final lasso regression model}
lasso_regression_coords_model_summer <- glmnet(x_lasso, y_lasso, family = "binomial", alpha = 1, lambda = lasso_regression_coords_lambda_summer$lambda.1se) 
# alpha = 0 ridge, 1 for lasso, between 0 and 1 for elastic 
#use $lambda.1se instead of $lambda.min for simpler but less flexible model

coef(lasso_regression_coords_model_summer)
```


 
# Normal Logistic Regression modeling 


```{r creating reg_predictions and quartiles}
set.seed(1234)

regression_model <- glm(Summerkill ~ Mean_Surf_Temp + Mean_Surf_Zscore +layer_dif + Schmidt + population + V1 + V2, family = 'binomial', data=main_data_census) 

coef(regression_model)
```



# Building datasets for shrinkage model outputs


#Building ridge  predictions dataset 


```{r}
ridge_summer_predictions <- dplyr::select(future_data_census, -FType, - FCode, - GNIS_Nm, - ReachCd, - Prmnn_I, - GNIS_ID,- Month, - Season, - Spring, - layer_dif, - quadratic_temp, - peak_temp, - long_round, - lat_round, - year, - Ice_Duration)


ridge_summer_predictions$Summerkill <- 0 # Not sure why I am forced to make this


newx<- model.matrix(Summerkill ~ . - Year - WBIC - site_id, ridge_summer_predictions) #why NEWX has to be a fake model and not just a dataset is unclear)


ridge_summer_predictions$Prob <- as.vector(predict(ridge_regression_model_summer, newx= newx, type = 'response'))


ridge_summer_predictions$quantile <- quantile(ridge_summer_predictions$Prob,probs = c(.01, 25, 75)/100, na.rm = TRUE)


```


```{r forecasting}
set.seed(1234)

a <- ridge_summer_predictions$Prob
simulation_log_regress <- rbinom(length(a), 1, prob = a)

ridge_summer_predictions$Summerkill_forecast <- simulation_log_regress


```


#Building lasso predictions set

```{r}

lasso_coords_summer_predictions <- dplyr::select(future_data_census, -FType, - FCode, - GNIS_Nm, - ReachCd, - Prmnn_I, - GNIS_ID, - Month, - Season, - Spring, - layer_dif, - quadratic_temp, - peak_temp, - long_round, - lat_round, - year, - Ice_Duration)

lasso_coords_summer_predictions$Summerkill <- 0 # Not sure why I am forced to make this

newx<- model.matrix(Summerkill ~ . - Year - WBIC - site_id, lasso_coords_summer_predictions) #why NEWX has to be a fake model and not just a dataset is unclear)



lasso_coords_summer_predictions$Prob <- as.vector(predict(lasso_regression_coords_model_summer, newx= newx, type = 'response'))


lasso_coords_summer_predictions$quantile <- quantile(lasso_coords_summer_predictions$Prob,probs = c(.01, 25, 75)/100, na.rm = TRUE)

```

```{r forecasting}
set.seed(1234)

a <- lasso_coords_summer_predictions$Prob
simulation_log_regress <- rbinom(length(a), 1, prob = a)

lasso_coords_summer_predictions$Summerkill_forecast <- simulation_log_regress

```

# Building Normal Regression Dataset


```{r}

reg_predictions <- future_data_census
reg_predictions$Prob <- predict(regression_model,future_data_census, type = 'response')
reg_predictions$quantile <- quantile(reg_predictions$Prob,probs = c(min(reg_predictions$Prob), max(reg_predictions$Prob)), na.rm = TRUE)



```

```{r forecasting}
set.seed(1234)

a <- reg_predictions$Prob
simulation_log_regress <- rbinom(length(a), 1, prob = a)

reg_predictions$Summerkill_forecast <- simulation_log_regress

```



# Testing Models

```{r creating 50% random split for training/testing}

set.seed(1234)

train_indices <- sample(1:nrow(modeling_data), size = 528339 , replace = FALSE) # 4/5ths = 528339 #half = 330212
train_data <- slice(modeling_data, train_indices) 
test_data  <- slice(modeling_data, -train_indices)


train_data_reg <- slice(main_data_census, train_indices) 
test_data_reg  <- slice(main_data_census, -train_indices)

#flds <- createFolds(main_data_census, k = 5, list = TRUE, returnTrain = TRUE)

```









# Ridge Regression summerkill testing - test/training


```{r}

x_train <- model.matrix(Summerkill ~ ., train_data) 


y_train <- ifelse(train_data$Summerkill == 1, 1, 0)

```

making training model

```{r}
ridge_regression_train <- glmnet(x_train, y_train, family = "binomial", alpha = 0, lambda = ridge_regression_lambda_summer$lambda.1se) # alpha = 0 ridge, 1 for lasso, between 0 and 1 for elastic 
#use lambda.1se instead of lambda.min for simpler but less flexible model
#can use lambda from regular model

#coef(lasso_regression_model)

``` 

testing for missclassification

```{r}

ridge_regression_test <- model.matrix(Summerkill ~ ., test_data)



probabilities <- ridge_regression_train %>% predict(newx = ridge_regression_test)
predicted_classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy 
observed_classes <- test_data$Summerkill
mean(predicted_classes == observed_classes)


```

testing for average probability seperation

```{r}

ridge_model_test <- test_data


ridge_model_test$Prob <- as.vector(predict(ridge_regression_train, newx= ridge_regression_test, type = 'response'))


ggplot(ridge_model_test, aes(x = factor(Summerkill), y = log(Prob))) +
  geom_boxplot()

ridge_model_test %>% group_by(Summerkill) %>% summarise(mean(Prob))

```

Testing for likelihood of fit


```{r}

ridge_model_test %>%
  summarise(likelihood = prod(ifelse(Summerkill == 1, Prob, (1-Prob))))


```


# Lasso COORDS + pop summerkill testing - test/training

Using training data from ridge regression

making training model

```{r}
lasso_coords_regression_train <- glmnet(x_train, y_train, family = "binomial", alpha = 1, lambda = lasso_regression_coords_lambda_summer$lambda.1se) # alpha = 0 ridge, 1 for lasso, between 0 and 1 for elastic 
#use lambda.1se instead of lambda.min for simpler but less flexible model
#can use lambda from regular model

#coef(lasso_regression_model)

``` 

testing for missclassification

```{r}



lasso_coords_regression_test <- model.matrix(Summerkill ~ . ,test_data)



probabilities <- lasso_coords_regression_train %>% predict(newx = lasso_coords_regression_test)
predicted_classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy 
observed_classes <- test_data$Summerkill
mean(predicted_classes == observed_classes)


```

testing for average probability seperation

```{r}

lasso_coords_model_test <- test_data


lasso_coords_model_test$Prob <- as.vector(predict(lasso_coords_regression_train, newx= lasso_coords_regression_test, type = 'response'))


ggplot(lasso_coords_model_test, aes(x = factor(Summerkill), y = log(Prob))) +
  geom_boxplot()

lasso_coords_model_test %>% group_by(Summerkill) %>% summarise(mean(Prob))

```

Testing for likelihood of fit

```{r}

lasso_coords_model_test%>%
  summarise(likelihood = prod(ifelse(Summerkill == 1, Prob, (1-Prob))))


```

# regular regression testing


making training model

```{r}
reg_train <- glm(Summerkill ~  Mean_Surf_Temp + Mean_Surf_Zscore + layer_dif + Schmidt + population + V1 + V2 , family = 'binomial', data=train_data_reg) 
``` 

testing for missclassification

```{r}



probabilities <- predict(reg_train, test_data_reg, type = 'response')
predicted_classes <- ifelse(probabilities > 0.5, 1, 0)
observed_classes <- test_data$Summerkill
mean(predicted_classes == observed_classes)


```

testing for average probability seperation

```{r}

reg_predictions_test <- test_data_reg

reg_predictions_test$Prob <- predict(reg_train, test_data_reg, type = 'response')




ggplot(reg_predictions_test, aes(x = factor(Summerkill), y = log(Prob))) +
  geom_boxplot()

reg_predictions_test %>% group_by(Summerkill) %>% summarise(mean(Prob))

```

Testing for likelihood of fit

```{r}

reg_predictions_test %>%
    summarise(likelihood = prod(ifelse(Summerkill == 1, Prob, (1-Prob))))

  

```




# User Model Data

```{r user data}

setwd(main_path)

Lake_Names <-read_excel("Input_Data/Wi_Lakes_Maps.xlsx") 

```

```{r}

setwd('/home/aatill/MME_Climate_Change_Research/Output_Data')

Lake_Risk_Assesment <- merge(dplyr::select(lasso_coords_summer_predictions,WBIC, site_id, Year, Prob, Mean_Surf_Temp), dplyr::select(Lake_Names, OFFICIAL_NAME, WBIC)) %>%
  filter(Year > 2020) %>%
  group_by(WBIC, site_id, Year, OFFICIAL_NAME) %>%
  summarise('Summerkill Probability' = sum(Prob), 'Mean Surface Temperature' = mean(Mean_Surf_Temp))

Lake_Risk_Assesment <- distinct(Lake_Risk_Assesment)

write.csv(Lake_Risk_Assesment, "Lake_Risk_Assessment.csv")

```
