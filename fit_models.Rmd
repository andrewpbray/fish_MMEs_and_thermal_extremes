---
title: "Fit Models"
author: "Aaron Till and Andrew Bray"
output: html_document
---

```{r}
library(tidyverse)
library(rsample)
library(caret)
library(glmnet)
library(Matrix)
library(e1071)
library(pROC)
library(PRROC) 
library(glmnetUtils)
library(doParallel)
library(lme4)
```

## Load prepared data

```{r}
setwd("data/prepared_for_modeling/")
training <- read_csv("training.csv",
                     col_types = list(wbic = col_character(),
                                      year = col_character(),
                                      month  = col_character(),
                                      season = col_character(),
                                      summerkill = col_character(),
                                      ice_duration = col_double())) %>%
  mutate(summerkill = as.factor(summerkill))

testing <- read_csv("testing.csv",
                    col_types = list(wbic = col_character(),
                                     year = col_character(),
                                     month  = col_character(),
                                     season = col_character(),
                                     ice_duration = col_double())) %>%
  mutate(summerkill = as.factor(summerkill))
```

## Specify variable sets

The first generalized model that we will consider is one using a subset of variables
selected based on their presumed effect and being mutually non-correlated (at least
strongly).

```{r}
f1 <- summerkill ~ variance_after_ice_30 + variance_after_ice_60 + log_schmidt +
  cumulative_above_10 + ice_duration + population + lon + lat + season + temp
```

The second model involves all covariates that we have at our disposal (except wbic,
which we treat separately because of the number of levels).

```{r}
f2 <- summerkill ~ variance_after_ice_30 + variance_after_ice_60 + log_schmidt +
  cumulative_above_10 + ice_duration + population + lon + lat + season + temp +
  max_bot + max_surf + mean_bot + mean_surf + max_bot_z + max_surf_z + mean_bot_z +
  mean_surf_z + layer_diff + quadratic_temp + peak_temp + cumulative_above_0 +
  cumulative_above_5
```


## Set up params for parameter selection

```{r}
control_logloss <- trainControl(method = "repeatedcv",
                                number = 5,
                                repeats = 2,
                                summaryFunction = mnLogLoss,
                                classProbs = TRUE)
control_logloss_ds <- trainControl(method = "repeatedcv",
                                   number = 5,
                                   repeats = 3,
                                   summaryFunction = mnLogLoss,
                                   classProbs = TRUE,
                                   sampling = "down")
```


## Lasso Logistic

We first fit LASSO models with many difference lambdas, utilizing a 5-fold CV
scheme, repeated once, on the training data.

### f1, logloss, no downsampling

```{r}
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

par_grid <-  expand.grid(alpha = 1,
                        lambda = seq(1.5e-6, 1e-5, 
                                     length.out = 6))

set.seed(825)
lasso_f1_logloss <- train(f1, 
                     data = training, 
                     method = "glmnet", 
                     metric = "mnLogLoss",
                     tuneGrid = par_grid,
                     trControl = control_logloss)
stopCluster(cl)
write_rds(lasso_f1_logloss, "../models/lasso_f1_logloss.rds")
```

### f1, logloss, with downsampling

```{r}
cl <- makePSOCKcluster(4)
registerDoParallel(cl)

par_grid <-  expand.grid(alpha = 1,
                        lambda = 10^seq(-3, -1, length = 10))

set.seed(825)
lasso_f1_logloss_downsampled <- train(f1, 
                                      data = training, 
                                      method = "glmnet", 
                                      metric = "mnLogLoss",
                                      tuneGrid = par_grid,
                                      trControl = control_logloss_ds)
stopCluster(cl)
write_rds(lasso_f1_logloss_downsampled, "../models/lasso_f1_logloss_downsampled.rds")
```

### f2, logloss, no downsampling

```{r}
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

#par_grid <-  expand.grid(alpha = 1,
                        # lambda = seq(1.5e-6, 1e-5, 
                        #              length.out = 6))

set.seed(825)
lasso_f2_logloss <- train(f2, 
                     data = training, 
                     method = "glmnet", 
                     metric = "mnLogLoss",
                     #tuneGrid = par_grid,
                     trControl = control_logloss)
stopCluster(cl)
write_rds(lasso_f2_logloss, "../models/lasso_f2_logloss.rds")
```

### f2, logloss, downsampled

```{r}
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

#par_grid <-  expand.grid(alpha = 1,
                        # lambda = seq(1.5e-6, 1e-5, 
                        #              length.out = 6))

set.seed(825)
lasso_f2_logloss_downsampled <- train(f2, 
                                      data = training, 
                                      method = "glmnet", 
                                      metric = "mnLogLoss",
                                      #tuneGrid = par_grid,
                                      trControl = control_logloss_ds)
stopCluster(cl)
write_rds(lasso_f2_logloss_downsampled, "../models/lasso_f2_logloss_downsampled.rds")
```


## Ridge logistic

### f1, logloss, no downsampling

```{r}
par_grid <-  expand.grid(alpha = 0,
                        lambda = seq(3.5e-7, 1.5e-5,
                                     length.out = 6))
cl <- makePSOCKcluster(6)
registerDoParallel(cl)
set.seed(825)
ridge_f1_logloss <- train(f1, 
                          data = training, 
                          method = "glmnet",
                          metric = "logLoss",
                          tuneGrid = par_grid,
                          trControl = control_logloss)
stopCluster(cl)
write_rds(ridge_f1_logloss, "../models/ridge_f1_logloss.rds")
```

### f1, logloss, with downsampling

```{r}
par_grid <-  expand.grid(alpha = 0,
                        lambda = seq(3.5e-8, 3.5e7,
                                     length.out = 8))
cl <- makePSOCKcluster(6)
registerDoParallel(cl)
set.seed(825)
ridge_f1_logloss_downsampled <- train(f1, 
                          data = training, 
                          method = "glmnet",
                          metric = "logLoss",
                          tuneGrid = par_grid,
                          trControl = control_logloss_ds)
stopCluster(cl)
write_rds(ridge_f1_logloss_downsampled, "../models/ridge_f1_logloss_downsampled.rds")
```

### f2, logloss, with downsampling

```{r}
par_grid <-  expand.grid(alpha = 0,
                        lambda = seq(1.8e-8, 3.5e-6, 
                                     length.out = 8))
cl <- makePSOCKcluster(8)
registerDoParallel(cl)

set.seed(825)
ridge_f2_logloss_downsampled <- train(f2, 
                     data = training, 
                     method = "glmnet", 
                     trControl = control_logloss_ds)
stopCluster(cl)
write_rds(ridge_f2_logloss_downsampled, "../models/ridge_f1_logloss_downsampled.rds")
```


## Random Effects Logistic

```{r}
f1_re <- summerkill ~ variance_after_ice_30 + variance_after_ice_60 + log_schmidt +
  cumulative_above_10 + ice_duration + population + lon + lat + season + temp + (1 | wbic)
```

```{r}
re_f1 <- glmer(f1_re,
               data = training, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)

library(optimx)
m1 <- lmer(f1_re, 
          data = training,
          family = binomial,
          REML = FALSE, 
          control = glmerControl(optimizer ='optimx',
                           optCtrl=list(method='L-BFGS-B')))

write_rds(re_f1, "../models/re_f1.rds")
```

